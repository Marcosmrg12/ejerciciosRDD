{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['INFO', 'Master:2566 - Started daemon with process name: 2788@debian'], ['INFO', 'SignalUtils:54 - Registered signal handler for TERM'], ['INFO', 'SignalUtils:54 - Registered signal handler for HUP'], ['INFO', 'SignalUtils:54 - Registered signal handler for INT'], ['INFO', 'SecurityManager:54 - Changing view acls to: hadoop'], ['INFO', 'SecurityManager:54 - Changing modify acls to: hadoop'], ['INFO', 'SecurityManager:54 - Changing view acls groups to: '], ['INFO', 'SecurityManager:54 - Changing modify acls groups to: '], ['INFO', 'SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users', 'with view permissions: Set(hadoop); groups with view permissions: Set(); users', 'with modify permissions: Set(hadoop); groups with modify permissions: Set()'], ['INFO', \"Utils:54 - Successfully started service 'sparkMaster' on port 7077.\"], ['INFO', 'Master:54 - Starting Spark master at spark://192.168.1.1:7077'], ['INFO', 'Master:54 - Running Spark version 2.4.0'], ['INFO', 'log:192 - Logging initialized @18919ms'], ['INFO', 'Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown'], ['INFO', 'Server:419 - Started @19444ms'], ['INFO', 'AbstractConnector:278 - Started ServerConnector@54d0539{HTTP/1.1,[http/1.1]}{0.0.0.0:8080}'], ['INFO', \"Utils:54 - Successfully started service 'MasterUI' on port 8080.\"], ['INFO', 'ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2a8f122{/driver/kill,null,AVAILABLE,@Spark}'], ['INFO', 'MasterWebUI:54 - Bound MasterWebUI to 0.0.0.0, and started at http://master:8080'], ['INFO', 'ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5c9fe261{/metrics/master/json,null,AVAILABLE,@Spark}'], ['INFO', 'ContextHandler:781 - Started o.s.j.s.ServletContextHandler@75894c70{/metrics/applications/json,null,AVAILABLE,@Spark}'], ['INFO', 'Master:54 - I have been elected leader! New state: ALIVE'], ['INFO', 'Master:54 - Registering worker 192.168.1.3:38127 with 2 cores, 1024.0 MB RAM'], ['INFO', 'Master:54 - Registering worker 192.168.1.2:34373 with 2 cores, 1024.0 MB RAM']]\n"
     ]
    }
   ],
   "source": [
    "info = sc.textFile('sparklog').map(lambda x: x.split('  ')).filter(lambda x: x[0]=='INFO').collect()\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['WARN', 'Utils:66 - Your hostname, debian resolves to a loopback address: 127.0.1.1; using 192.168.1.1 instead (on interface ens33)'], ['WARN', 'NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable']]\n"
     ]
    }
   ],
   "source": [
    "warning = sc.textFile('sparklog').map(lambda x: x.split('  ')).filter(lambda x: x[0]=='WARN').collect()\n",
    "print(warning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ERROR', 'Master:43', '-', 'RECEIVED', 'SIGNAL', 'TERM']]\n"
     ]
    }
   ],
   "source": [
    "error = sc.textFile('sparklog').map(lambda x: x.split(' ')).filter(lambda x: x[0]=='ERROR').collect()\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
